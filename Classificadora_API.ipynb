{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0e6639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'clf__C': 1, 'tfidf__max_df': 0.8, 'tfidf__ngram_range': (1, 1)}\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "Post  com Potencial Suicida       0.94      0.92      0.93       264\n",
      "           Post Não Suicida       0.92      0.94      0.93       270\n",
      "\n",
      "                   accuracy                           0.93       534\n",
      "                  macro avg       0.93      0.93      0.93       534\n",
      "               weighted avg       0.93      0.93      0.93       534\n",
      "\n",
      "Tweet 6677643aacc171c6b0cebe21 atualizado com sucesso.\n",
      "Tweet 66776442acc171c6b0cebe25 atualizado com sucesso.\n",
      "Tweet 66776450acc171c6b0cebe29 atualizado com sucesso.\n",
      "Tweet 667773fcacc171c6b0cebe2e atualizado com sucesso.\n",
      "Tweet 667773fcacc171c6b0cebe32 atualizado com sucesso.\n",
      "Tweet 667773fdacc171c6b0cebe36 atualizado com sucesso.\n",
      "Tweet 667773fdacc171c6b0cebe3a atualizado com sucesso.\n",
      "Tweet 667773feacc171c6b0cebe3e atualizado com sucesso.\n",
      "Tweet 667773ffacc171c6b0cebe42 atualizado com sucesso.\n",
      "Tweet 667773ffacc171c6b0cebe46 atualizado com sucesso.\n",
      "Tweet 66777400acc171c6b0cebe4a atualizado com sucesso.\n",
      "Tweet 66777400acc171c6b0cebe4e atualizado com sucesso.\n",
      "Tweet 66777401acc171c6b0cebe52 atualizado com sucesso.\n",
      "Tweet 66777401acc171c6b0cebe56 atualizado com sucesso.\n",
      "Tweet 66777402acc171c6b0cebe5a atualizado com sucesso.\n",
      "Tweet 66777402acc171c6b0cebe5e atualizado com sucesso.\n",
      "Tweet 66777403acc171c6b0cebe62 atualizado com sucesso.\n",
      "Tweet 66777404acc171c6b0cebe66 atualizado com sucesso.\n",
      "Tweet 66777404acc171c6b0cebe6a atualizado com sucesso.\n",
      "Tweet 66777405acc171c6b0cebe6e atualizado com sucesso.\n",
      "Tweet 66777405acc171c6b0cebe72 atualizado com sucesso.\n",
      "Tweet 66777406acc171c6b0cebe76 atualizado com sucesso.\n",
      "Tweet 6677741aacc171c6b0cebe7b atualizado com sucesso.\n",
      "Tweet 6677741bacc171c6b0cebe7f atualizado com sucesso.\n",
      "Tweet 6677741bacc171c6b0cebe83 atualizado com sucesso.\n",
      "Tweet 6677741cacc171c6b0cebe87 atualizado com sucesso.\n",
      "Tweet 6677741cacc171c6b0cebe8b atualizado com sucesso.\n",
      "Tweet 6677741dacc171c6b0cebe8f atualizado com sucesso.\n",
      "Tweet 6677741eacc171c6b0cebe93 atualizado com sucesso.\n",
      "Tweet 6677741facc171c6b0cebe97 atualizado com sucesso.\n",
      "Tweet 6677741facc171c6b0cebe9b atualizado com sucesso.\n",
      "Tweet 66777420acc171c6b0cebe9f atualizado com sucesso.\n",
      "Tweet 66777420acc171c6b0cebea3 atualizado com sucesso.\n",
      "Tweet 66777421acc171c6b0cebea7 atualizado com sucesso.\n",
      "Tweet 66777421acc171c6b0cebeab atualizado com sucesso.\n",
      "Tweet 66777422acc171c6b0cebeaf atualizado com sucesso.\n",
      "Tweet 66777422acc171c6b0cebeb3 atualizado com sucesso.\n",
      "Tweet 66777423acc171c6b0cebeb7 atualizado com sucesso.\n",
      "Tweet 66777423acc171c6b0cebebb atualizado com sucesso.\n",
      "Tweet 66777424acc171c6b0cebebf atualizado com sucesso.\n",
      "Tweet 66777424acc171c6b0cebec3 atualizado com sucesso.\n",
      "Tweet 66777425acc171c6b0cebec7 atualizado com sucesso.\n",
      "Tweet 66777425acc171c6b0cebecb atualizado com sucesso.\n",
      "Tweet 66777426acc171c6b0cebecf atualizado com sucesso.\n",
      "Tweet 66777426acc171c6b0cebed3 atualizado com sucesso.\n",
      "Tweet 66777427acc171c6b0cebed7 atualizado com sucesso.\n",
      "Tweet 66777427acc171c6b0cebedb atualizado com sucesso.\n",
      "Tweet 66777428acc171c6b0cebedf atualizado com sucesso.\n",
      "Tweet 66777428acc171c6b0cebee3 atualizado com sucesso.\n",
      "Tweet 66777429acc171c6b0cebee7 atualizado com sucesso.\n",
      "Tweet 66777429acc171c6b0cebeeb atualizado com sucesso.\n",
      "Tweet 667777f2acc171c6b0cebef2 atualizado com sucesso.\n",
      "Tweet 667777f3acc171c6b0cebef6 atualizado com sucesso.\n",
      "Tweet 667777f3acc171c6b0cebefa atualizado com sucesso.\n",
      "Tweet 667777f4acc171c6b0cebefe atualizado com sucesso.\n",
      "Tweet 667777f4acc171c6b0cebf02 atualizado com sucesso.\n",
      "Tweet 667777f5acc171c6b0cebf06 atualizado com sucesso.\n",
      "Tweet 667777f5acc171c6b0cebf0a atualizado com sucesso.\n",
      "Tweet 667777f6acc171c6b0cebf0e atualizado com sucesso.\n",
      "Tweet 667777f6acc171c6b0cebf12 atualizado com sucesso.\n",
      "Tweet 667777f7acc171c6b0cebf16 atualizado com sucesso.\n",
      "Tweet 667777f7acc171c6b0cebf1a atualizado com sucesso.\n",
      "Tweet 667777f8acc171c6b0cebf1e atualizado com sucesso.\n",
      "Tweet 667777f8acc171c6b0cebf22 atualizado com sucesso.\n",
      "Tweet 667777f9acc171c6b0cebf26 atualizado com sucesso.\n",
      "Tweet 667777f9acc171c6b0cebf2a atualizado com sucesso.\n",
      "Tweet 667777faacc171c6b0cebf2e atualizado com sucesso.\n",
      "Tweet 667777faacc171c6b0cebf32 atualizado com sucesso.\n",
      "Tweet 667777fbacc171c6b0cebf36 atualizado com sucesso.\n",
      "Tweet 667777fbacc171c6b0cebf3a atualizado com sucesso.\n",
      "Tweet 667777fcacc171c6b0cebf3e atualizado com sucesso.\n",
      "Tweet 667777fcacc171c6b0cebf42 atualizado com sucesso.\n",
      "Tweet 667777fdacc171c6b0cebf46 atualizado com sucesso.\n",
      "Tweet 667777fdacc171c6b0cebf4a atualizado com sucesso.\n",
      "Tweet 667777feacc171c6b0cebf4e atualizado com sucesso.\n",
      "Tweet 667777feacc171c6b0cebf52 atualizado com sucesso.\n",
      "Tweet 667777ffacc171c6b0cebf56 atualizado com sucesso.\n",
      "Tweet 667777ffacc171c6b0cebf5a atualizado com sucesso.\n",
      "Tweet 66777800acc171c6b0cebf5e atualizado com sucesso.\n",
      "Tweet 66777800acc171c6b0cebf62 atualizado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Baixar recursos adicionais do NLTK\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Carregar os dados\n",
    "data = pd.read_excel('Expanded_Dataset_Tweets.xlsx')\n",
    "\n",
    "# Pré-processamento do texto\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    processed_text = ' '.join(tokens)\n",
    "    return processed_text\n",
    "\n",
    "data['processed_tweets'] = data['tweets'].apply(preprocess_text)\n",
    "\n",
    "# Dividir os dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['processed_tweets'], data['classificador'], test_size=0.55, random_state=42)\n",
    "\n",
    "# Criar o pipeline de classificação\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "# Definir os hiperparâmetros para o GridSearch\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.8, 0.9, 1.0],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'clf__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Realizar o GridSearch com validação cruzada\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir os melhores hiperparâmetros\n",
    "print(f\"Melhores hiperparâmetros: {grid_search.best_params_}\")\n",
    "\n",
    "# Avaliar o modelo com os melhores hiperparâmetros\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "predictions = best_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "\n",
    "# URL da sua API\n",
    "login_url = 'http://localhost:3000/auth/login'\n",
    "# Credenciais do usuário\n",
    "credentials = {\n",
    "    'usuario': 'admin',\n",
    "    'senha': 'admin'\n",
    "}\n",
    "\n",
    "# Fazendo uma solicitação POST para obter o token JWT\n",
    "login_response = requests.post(login_url, json=credentials)\n",
    "token = login_response.json()['token']\n",
    "# Incluindo o token JWT no cabeçalho Authorization\n",
    "headers = {\n",
    "    'Authorization': \"Bearer \"+token\n",
    "}\n",
    "\n",
    "# Função para classificar tweets e atualizar no banco de dados\n",
    "def classify_and_update_tweets(api_url):\n",
    "    # Obter tweets da API\n",
    "    response = requests.get(f\"{api_url}/tweets\", headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            tweets = response.json()\n",
    "        except ValueError:\n",
    "            print(\"Erro ao decodificar JSON. Resposta não está no formato JSON.\")\n",
    "            return\n",
    "        \n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet['texto']  # Ajuste este campo conforme a estrutura do seu JSON\n",
    "            processed_text = preprocess_text(tweet_text)\n",
    "            is_suicida = best_pipeline.predict([processed_text])[0] == 'Post  com Potencial Suicida'\n",
    "            \n",
    "            # Atualizar o campo isSuicida no tweet\n",
    "            tweet_id = tweet['_id']  # Ajuste este campo conforme a estrutura do seu JSON\n",
    "            update_url = f\"{api_url}/tweets/{tweet_id}\"\n",
    "            update_data = {'isSuicida': is_suicida}\n",
    "            update_response = requests.put(update_url, json=update_data, headers=headers)\n",
    "            \n",
    "            if update_response.status_code == 200:\n",
    "                print(f\"Tweet {tweet_id} atualizado com sucesso.\")\n",
    "            else:\n",
    "                print(f\"Erro ao atualizar o tweet {tweet_id}. Código de status:\", update_response.status_code)\n",
    "    else:\n",
    "        print(\"Erro ao acessar a API. Código de status:\", response.status_code)\n",
    "\n",
    "# Definir URL da API\n",
    "api_url = \"http://localhost:3000\"\n",
    "\n",
    "# Classificar e atualizar tweets\n",
    "classify_and_update_tweets(api_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e10af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
